# ProgettoLab
# introduzione
L'obiettivo del progetto è quello di creare un classificatori di immagini, dove le immagini sono gesti presi dall' "american sign language", il linguaggio dei segni predominante per i non udenti in America. il Dataset presente nel codice è stato creato da me attravero l'utilizzo di 6 persone differenti (in modo da non creare overfitting su una sola persona) di età e sesso diverse ai quali ho scattatato 4500 foto, sono perciò 300 foto a segno per 15 segni totali. Tuttavia ho deciso di eseguire test su entrambi le mani, perciò le foto sono state scattate in egual numero sia alla mano destra che sinistra a tutti i partecipanti delle foto.
# utilizzo di librerie
Passando alle cose tecniche, ho deciso di utilizzare la libreria cvzone per quanto riguarda la parte di computer vision, ovvero la parte dove riconosco e trovo le mani all'interno di una foto o di un video o in real time attraverso la webcam, mentre ho utilizzato la libreria Keras per l'utilizzo di configurazioni di reti neurali.
# prima fase (Computer Vision)
Nella prima fase del mio progetto mi sono concentrato sulla parte di costruzione del dataset, perciò sfruttando la libreria cvzone sono riuscito ad individuare immediatamente le mani in una foto o nella web attraverso la funzione findHands(). Questa funzione restituisce molte informazioni utili della mano,tra cui la posizione all'interno della foto. Ho salvato cosi la posizione della mano all'interno di alcune variabile e creato una nuova immagine, ovvero "imgCrop" con le dimensioni appena raccolte, questa nuova immagine conterrà solamente la mano appena individuata. Tuttavia ora era presente il problema della dimensione dell'immagine, in quanto ovviamente non possono avere tutte la stessa dimensioni, a causa dell'inclinazione della mano e della diverisità di segni, cosi ho deciso di creare una terza immagine "imgWhite" il quale è una copia di imgCrop ma presenta sempre dimensione (400, 400), ciò avviene attraverso l'utilizzo di una "cornice" bianca inserita nell'immagine. se imgCrop presenta altezza > larghezza allora la cornice verrà inserita in larghezza e l'immagine della mano verrà messa proprio al centro della foto, analoga cosa in maniera speculare viene fatta se larghezza>altezza. Come ultima cosa ho assegnato dei tasti per la chiusura della webcam (ovvero "e") attraverso la funzione cap.release() e cv2.destroyAllWindows(), e per scattare le foto (attraverso il tasto "s") attraverso la funzione imwrite() , la quale inserisce nella cartella indicata con come parametro la foto scattata, cartella la quale possediede il nome della label corrispondente al segno 
# seconda fase (Deep Learning)
Il mio dataset era ora formato da una cartella principale e sottocartelle, ognuna contentenete il nome della label corrispondente con le foto ad esse dedicate, perciò attraverso la funzione di keras image_dataset_from_directory ho formato un un dataset che potesse essere utilizzato dalla mia rete neurale, questo infatti possedeva un array contentente l'immagine in forma di array e un secondo array che aveva nello stesso indice la label corretta. Ho diviso poi il dataset in tre: train set (70%), validation set(20%), test set(10%). Ho poi creato la mia rete neurale e poichè il modello scelto da me aveva un solo input al quale corrispondeva un solo output ho scelto il sequential model per poi andare a specificare i miei sottolivelli. La rete è composta da 3 strati di convoluzioni, quindi 3 blocchi che si occuopano della vera e propria analisi dell'immagine, i tre strati possiedono filtri di dimensioni (3,3) e che si muovono di un passo alla volta nell'immagine, tuttavia mentre il primo e terzo hanno 16 filtri, il secondo ne possiede 32, esse inoltre possiedono come funzione di attivazione la funzione ReLu che quindi pone a 0 i valori negativi mentre lascia inalterati i positivi. Queste tre fasi di convoluzioni sono intervallate da 3 MaxPooling2D ovvero tre fasi dove si riduce la frequenza di campionamento sia in altezza che in larghezza, si riducono le dimensioni mantenendo però le informazioni principali. Successivamente a questi strati di convoluzioni è presente uno strato di flatten, necessario in questo caso per poter mettere tutti i dati in una dimensione solo, ed infine ci sono due strati di dense necessari per creare degli stati completamente connessi, di cui l'ultimo fondamentale in quanto il numero di neuroni inseriti deve corrispondere al numeri di classi presenti nel progetto, l'ultimo strato inoltre differentementi dagli altri presenta la funzione di attivazione='softmax' utilizzata per gli algoritmi multiclassi, infatti questa funzione comprime un vettore di k-dimensioni in valori compresi tra 0 e 1 e nasconde i valori più piccoli dando maggiore peso a quelli che hanno un valore più grande. Ho utilizzato la funzione SparseCategoricalCrossEntropy e una funzione di ottimizzazione Adam. Successivamente attraverso la funzione di fit della libreria keras ho eseguito la vera fase di apprendimento dell'algoritmo, passandogli all'algoritmo creato il train set(creato precedentemente), il validation set per testare l'algoritmo su nuove foto e vedere la sua accuratezza e il numero di epoche (=10, ovvero il numero di cicli eseguiti sui dati di allenamemto).
# evaluation model
Attraverso la costruzione del grafico di loss e del grafico dell'accuracy ho potuto vedere l'andamento della mia rete neurale e si è potuto notare che ho un accuracy del 98% per il test e circa il 97% per il validation set, mentre una loss di circa 0.05 per il test e 0.1 per il validation set. inoltre attraverso la costruzione della matrice di confusione, creata attraverso la predict su un nuovo set (test set) sono riuscito ad individuare quali gesti possiedono una precisione maggiore e quali sono scambiati per altri. Per un ulteriore valutazione del modello creato ho eseguito la funzione classification_report, il quale ci fornisce altre valutazioni sul modello, ovvero precision, recall e f1-score, dove precisione è il rapporto tra true positive/(true positive+false positive), recall è true positive/(true positive+false negative), mentre f1 score è la media armonica tra la precision e la recall. come ultimo test che ho voluto eseguire è quello su una webcam, l'immagine trasmessa viene analizzata del test attraverso la predict e appare su schermo la label predetta.